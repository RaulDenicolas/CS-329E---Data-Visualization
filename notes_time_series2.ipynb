{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a60e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca854dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frame\n",
    "df = pd.read_csv ('AirPassengers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5421ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column Date to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert format\n",
    "df['Date'] = df['Date'].dt.strftime('%Y-%m')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88cba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "ax = sns.lineplot (x = 'Date', y = '#Passengers', data = df, color = 'r')\n",
    "ax.set_title ('Airline Passengers from 1949 to 1960')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37908188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(df, x, y, title=\"\", xlabel='Date', ylabel='Number of Passengers', dpi=100):\n",
    "    plt.figure(figsize=(15,4), dpi=dpi)\n",
    "    plt.plot(x, y, color='tab:red')\n",
    "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "plot_df(df, x=df['Date'], y=df['#Passengers'], \n",
    "        title='Number of Airline passengers from 1949 to 1960')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7785221",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Date'].values\n",
    "y1 = df['#Passengers'].values\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16,5), dpi= 120)\n",
    "plt.fill_between(x, y1=y1, y2=-y1, alpha=0.5, linewidth=2, color='seagreen')\n",
    "plt.ylim(-800, 800)\n",
    "plt.title('Air Passengers (Two Side View)', fontsize=16)\n",
    "plt.hlines(y=0, xmin=np.min(df['Date']), xmax=np.max(df['Date']), linewidth=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404bedcb",
   "metadata": {},
   "source": [
    "##### Patterns in a Time Series\n",
    "* Time Series = Base Level + Trend + Seasonality + Error  \n",
    "* Trend = there is an increasing or decreasing slope in the time series   \n",
    "* Seasonality = there is a distinct repeated pattern observed between regular intervals due to seasonal factors. It could be because of the month of the year, the day of the month, weekdays or even time of the day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca35d94",
   "metadata": {},
   "source": [
    "###### Additive time series\n",
    "Value = Base Level + Trend + Seasonality + Error\n",
    "\n",
    "###### Multiplicative Time Series:\n",
    "Value = Base Level x Trend x Seasonality x Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bfffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# Multiplicative Decomposition \n",
    "multiplicative_decomposition = seasonal_decompose(df['#Passengers'], model='multiplicative', period=30)\n",
    "\n",
    "# Additive Decomposition\n",
    "additive_decomposition = seasonal_decompose(df['#Passengers'], model='additive', period=30)\n",
    "\n",
    "# Plot\n",
    "plt.rcParams.update({'figure.figsize': (16,12)})\n",
    "multiplicative_decomposition.plot().suptitle('Multiplicative Decomposition', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "additive_decomposition.plot().suptitle('Additive Decomposition', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502d41ba",
   "metadata": {},
   "source": [
    "##### Stationary and Non-Stationary Time Series\n",
    "* A stationary series is one where the values of the series is not a function of time.\n",
    "* In a stationary series like mean, variance and autocorrelation are constant over time. \n",
    "* Autocorrelation is the correlation of the series with its previous values.\n",
    "* A stationary time series is independent of seasonal effects as well.\n",
    "* We can covert any non-stationary time series into a stationary one by applying a suitable transformation. \n",
    "* Most statistical forecasting methods are designed to work on a stationary time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac50583",
   "metadata": {},
   "source": [
    "##### Steps to make the series stationary\n",
    "* Differencing the Series (once or more)\n",
    "* Take the log of the series\n",
    "* Take the nth root of the series\n",
    "* Combination of the aboveSteps to make a series stationary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf91b1c",
   "metadata": {},
   "source": [
    "###### Steps in Differencing\n",
    "* If Y(t) is the value at time t, then the first difference of Y = Y(t) – Y(t-1). \n",
    "* Differencing the series is nothing but subtracting the next value by the current value.\n",
    "* If the first difference doesn’t make a series stationary, we can go for the second differencing and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cac1b6",
   "metadata": {},
   "source": [
    "###### Reasons to convert to stationary\n",
    "* Forecasting a stationary series is relatively easy and the forecasts are more reliable.\n",
    "* Autoregressive forecasting models are essentially linear regression models that utilize the lag(s) of the series itself as predictors.\n",
    "* Linear regression works best if the predictors (X variables) are not correlated against each other. Stationarizing the series solves this problem since it removes any persistent autocorrelation, thereby making the predictors(lags of the series) in the forecasting models nearly independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf5832b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### Tests for Stationarity\n",
    "* The stationarity of a series can be checked by looking at the plot of the series.\n",
    "* Another method is to split the series into 2 or more contiguous parts and computing the summary statistics like the mean, variance and the autocorrelation. If the stats are quite different, then the series is not likely to be stationary.\n",
    "* Quantitative methods can be used to determine if a given series is stationary or not, like Unit Root Tests. \n",
    "* There are multiple implementations of Unit Root tests like:\n",
    "    * Augmented Dickey Fuller test (ADF Test)\n",
    "    * Kwiatkowski-Phillips-Schmidt-Shin – KPSS test (trend stationary)\n",
    "    * Philips Perron test (PP Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe622673",
   "metadata": {},
   "source": [
    "###### Augmented Dickey Fuller test (ADF Test) \n",
    "Augmented Dickey Fuller test or (ADF Test) is the most commonly used test to detect stationarity. Here, we assume that the null hypothesis is the time series possesses a unit root and is non-stationary. Then, we collect evidence to support or reject the null hypothesis. So, if we find that the p-value in ADF test is less than the significance level (0.05), we reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c2431",
   "metadata": {},
   "source": [
    "###### Kwiatkowski-Phillips-Schmidt-Shin – KPSS test (trend stationary)  \n",
    "The KPSS test, on the other hand, is used to test for trend stationarity. The null hypothesis and the P-Value interpretation is just the opposite of ADH test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38abb6ad",
   "metadata": {},
   "source": [
    "###### Philips Perron test (PP Test)  \n",
    "The Philips Perron or PP test is a unit root test. It is used in the time series analysis to test the null hypothesis that a time series is integrated of order 1. It is built on the ADF test discussed above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7496b85d",
   "metadata": {},
   "source": [
    "##### Difference between White Noise and Stationary Series\n",
    "* The white noise is not a function of time. Its mean and variance does not change over time. * Unlike a stationary series, the white noise is completely random with a mean of 0. In white noise there is no pattern.\n",
    "* A sequence of completely random numbers with a mean of zero is a white noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of random numbers\n",
    "rand_numbers = np.random.randn(1000)\n",
    "pd.Series(rand_numbers).plot(title='Random White Noise', color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5599968",
   "metadata": {},
   "source": [
    "##### Detrend a Time Series\n",
    "Detrending a time series means to remove the trend component from the time series. There are multiple approaches of doing this as listed below:\n",
    "* Subtract the line of best fit from the time series. The line of best fit may be obtained from a linear regression model with the time steps as the predictor. For more complex trends, we may want to use quadratic terms (x^2) in the model.\n",
    "* We subtract the trend component obtained from time series decomposition.\n",
    "* Subtract the mean.\n",
    "* Apply a filter like Baxter-King filter(statsmodels.tsa.filters.bkfilter) or the Hodrick-Prescott Filter (statsmodels.tsa.filters.hpfilter) to remove the moving average trend lines or the cyclical components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract the line of best fit from the time series\n",
    "from scipy import signal\n",
    "detrended = signal.detrend(df['#Passengers'].values)\n",
    "plt.plot(detrended)\n",
    "plt.title('Air Passengers detrended by subtracting the least squares fit', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de954492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a statsmodel to subtract the trend component\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "result_mul = seasonal_decompose(df['#Passengers'], model='multiplicative', period=30)\n",
    "detrended = df['#Passengers'].values - result_mul.trend\n",
    "plt.plot(detrended)\n",
    "plt.title('Air Passengers detrended by subtracting the trend component', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a31836",
   "metadata": {},
   "source": [
    "##### Deseasonalize a Time Series\n",
    "There are multiple approaches to deseasonalize a time series. These approaches are listed below:\n",
    "* Take a moving average with length as the seasonal window. This will smoothen in series in the process.\n",
    "* Seasonal difference the series (subtract the value of previous season from the current value).\n",
    "* Divide the series by the seasonal index obtained from STL decomposition. If dividing by the seasonal index does not work well, we will take a log of the series and then do the deseasonalizing. We will later restore to the original scale by taking an exponential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6ee652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtracting the Trend Component\n",
    "\n",
    "# Time Series Decomposition\n",
    "result_mul = seasonal_decompose(df['#Passengers'], model='multiplicative', period=30)\n",
    "\n",
    "# Deseasonalize\n",
    "deseasonalized = df['#Passengers'].values / result_mul.seasonal\n",
    "\n",
    "# Plot\n",
    "plt.plot(deseasonalized)\n",
    "plt.title('Air Passengers Deseasonalized', fontsize=16)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4194ce07",
   "metadata": {},
   "source": [
    "##### Test for Seasonality of a Time Series\n",
    "The common way to test for seasonality of a time series is to plot the series and check for repeatable patterns in fixed time intervals. So, the types of seasonality is determined by the clock or the calendar.\n",
    "* Hour of day\n",
    "* Day of month\n",
    "* Weekly\n",
    "* Monthly\n",
    "* Yearly  \n",
    "However, if we want a more definitive inspection of the seasonality, use the Autocorrelation Function (ACF) plot. If there is a strong seasonal pattern, the ACF plot usually reveals definitive repeated spikes at the multiples of the seasonal window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for seasonality\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "# Draw Plot\n",
    "plt.rcParams.update({'figure.figsize':(10,6), 'figure.dpi':120})\n",
    "autocorrelation_plot(df['#Passengers'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d929232",
   "metadata": {},
   "source": [
    "##### Autocorrelation and Partial Autocorrelation Functions \n",
    "* Autocorrelation is simply the correlation of a series with its own lags. If a series is significantly autocorrelated, that means, the previous values of the series (lags) may be helpful in predicting the current value.\n",
    "* Partial Autocorrelation also conveys similar information but it conveys the pure correlation of a series and its lag, excluding the correlation contributions from the intermediate lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c4ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Draw Plot\n",
    "fig, axes = plt.subplots(1,2,figsize=(16,3), dpi= 100)\n",
    "plot_acf(df['#Passengers'].tolist(), lags=50, ax=axes[0])\n",
    "plot_pacf(df['#Passengers'].tolist(), lags=50, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e4874",
   "metadata": {},
   "source": [
    "##### Computation of Partial Autocorrelation Function\n",
    "* The partial autocorrelation function of lag (k) of a series is the coefficient of that lag in the autoregression equation of Y. The autoregressive equation of Y is the linear regression of Y with its own lags as predictors.\n",
    "* For example, if Y(t) is the current series and Y(t-1) is the lag 1 of Y, then the partial autocorrelation of lag 3 (Y(t-3)) is the coefficient a3 of Y(t-3) in the following equation: \n",
    "\n",
    "Y(t) = a0 + a1 * Y(t-1) + a2 * Y(t-2) + a3 * Y(t-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54768b3",
   "metadata": {},
   "source": [
    "##### Lag Plots\n",
    "A Lag plot is a scatter plot of a time series against a lag of itself. It is normally used to check for autocorrelation. If there is any pattern existing in the series, the series is autocorrelated. If there is no such pattern, the series is likely to be random white noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import lag_plot\n",
    "plt.rcParams.update({'ytick.left' : False, 'axes.titlepad':10})\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10,3), sharex=True, sharey=True, dpi=100)\n",
    "for i, ax in enumerate(axes.flatten()[:4]):\n",
    "    lag_plot(df['#Passengers'], lag=i+1, ax=ax, c='firebrick')\n",
    "    ax.set_title('Lag ' + str(i+1))\n",
    "\n",
    "fig.suptitle('Lag Plots of Air Passengers', y=1.05)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0632125",
   "metadata": {},
   "source": [
    "##### Smoothening a Time Series\n",
    "Smoothening of a time series may be useful in the following circumstances:\n",
    "* Reducing the effect of noise in a signal get a fair approximation of the noise-filtered series.\n",
    "* The smoothed version of series can be used as a feature to explain the original series itself.\n",
    "* Visualize the underlying trend better. \n",
    "* We can smoothen a time series using the following methods:\n",
    "    * Take a moving average\n",
    "    * Do a LOESS smoothing (Localized Regression)\n",
    "    * Do a LOWESS smoothing (Locally Weighted Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18039bc9",
   "metadata": {},
   "source": [
    "###### Moving Average\n",
    "Moving average is the average of a rolling window of defined width. We must choose the window-width wisely, because, large window-size will over-smooth the series. For example, a window-size equal to the seasonal duration (ex: 12 for a month-wise series), will effectively nullify the seasonal effect.\n",
    "\n",
    "###### Localized Regression\n",
    "LOESS, short for ‘Localized Regression’ fits multiple regressions in the local neighborhood of each point. It is implemented in the statsmodels package, where you can control the degree of smoothing using frac argument which specifies the percentage of data points nearby that should be considered to fit a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6cd72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
